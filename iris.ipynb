{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://vlegalwaymayo.atu.ie/pluginfile.php/1/theme_catawesome/logo/1708672446/logo.svg\" width=20% height=20%>\n",
    "\n",
    "# Analysis of Iris Dataset\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an overwiev of my project about analysis of well-known Iris Dataset as part of the assessment project for Programming and Scripting module on Higher Diploma in Data Analytics course from [ATU](https://www.atu.ie/) in Summer 2023/24.\n",
    "\n",
    "I will explain my approach to the solution of given tasks, my research and references for the code I wrote and results of my analysis. \n",
    "\n",
    "The program is written in the file [**analysis.py**](https://github.com/mondbr/pands-project/blob/main/analysis.py) saved in this repository. The file also contains comments to the code I wrote. \n",
    " \n",
    "\n",
    "\n",
    "*author: Monika Dabrowska, May 2024*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/360px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\" alt=\"Iris Setosa\" style=\"width: 310px;\">\n",
    "    <p style=\"font-size: 20px;\">Iris Setosa photo by Radomil via Wikipedia</p>\n",
    "  </div>\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/640px-Iris_versicolor_3.jpg\" alt=\"Iris Versicolor\" style=\"width: 570px;\">\n",
    "    <p style=\"font-size: 20px;\">Iris Versicolor photo by Dlanglois Wikipedia</p>\n",
    "  </div>\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/736px-Iris_virginica.jpg\" alt=\"Iris Virginica\" style=\"width: 500px;\">\n",
    "    <p style=\"font-size: 20px;\">Iris Virginica photo by Frank Mayfield via Wikipedia</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Iris Dataset (History)\n",
    "***\n",
    "\n",
    "The *Iris flower dataset*, also known as *Fiher's Iris dataset* is a [multivariate](https://en.wikipedia.org/wiki/Multivariate_statistics) dataset popularized by British statistitian and biologist [Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) in his 1936 publication *The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis*. The free access to the full article in PDF in online library can be found [here](https://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x). \n",
    "\n",
    "In this article, Fisher developed and evaluated a linear function to differentiate Iris species based on the morphology of their flowers. It was the first time that the sepal and petal measures of the three Iris species as mentioned above appeared publicly.\n",
    "\n",
    "The majority of the data was collected by [Edgar Anderson](https://en.wikipedia.org/wiki/Edgar_Anderson) to quantify the morphological variation of Iris flowers from three related species - *Iris setosa*, *Iris virginica* and *Iris versicolor*. Two of the three species were collected in the [Gaspé Peninsula](https://en.wikipedia.org/wiki/Gasp%C3%A9_Peninsula) region in Canada, with all samples taken from the same pasture, picked on the same day, and measured by the same person using the same apparatus. This careful collection method ensured consistency and accuracy in the measurements.\n",
    "\n",
    "The data contains an information of 50 samples from each of three species and its four features - the length and the width of the sepals and petals, in centimeters. \n",
    "\n",
    "The Iris data has  become a widely used tool for pattern recognition and classification tasks across various fields, including machine learning, analysis, statistics, and biology.\n",
    "\n",
    "*(source: [wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set))*\n",
    "\n",
    "\n",
    "Iris flower features are pictured below: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"https://media.licdn.com/dms/image/D5612AQFvpSLdhkfa0g/article-cover_image-shrink_600_2000/0/1694107215197?e=2147483647&v=beta&t=aSiPQP37OssvFRNT_Gjf95WZfTlr5CB3n_apgLGLrqo\" width=30% height=30%>\n",
    "<div style=\"text-align:center; font-size:10px;\"><p>Photo from Hani Abudaba on LinkedIn</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset file\n",
    "***\n",
    "\n",
    "The Iris flower dataset contains a set of 150 individual records which represents three Iris spiecies:\n",
    "- Iris Setosa - 50 samples\n",
    "- Iris Virginica - 50 samples\n",
    "- Iris Versicolor - 50 samples\n",
    "\n",
    "The columns represents plant features such as:\n",
    "- Sepal Lenght in cm\n",
    "- Sepal Width in cm\n",
    "- Petal Lenght in cm\n",
    "- Petal Width in cm\n",
    "\n",
    "The Iris flowers data was downloaded from [mwaskom/seaborn on Github](https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv) and loaded to the *[analysis.py](https://github.com/mondbr/pands-project/blob/main/analysis.py)* file in this repository. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Analysis - libraries and code\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I will explain the necessary libraries imported that are needed for this analysis, the dataset import and the code to write a script for summary creation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing nessesary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**pandas**](https://www.w3schools.com/python/pandas/pandas_intro.asp#:~:text=Pandas%20is%20a%20Python%20library,by%20Wes%20McKinney%20in%202008.) is a Python library that is used for workings with datasets. It offers a range of functions for analyzing, cleaning, exploring, and manipulating data. The name \"Pandas\" references both \"Panel Data\" and \"Python Data Analysis.\" The library was created by Wes McKinney in 2008.\n",
    "In this project *pandas* is used for creating a summary of the dataset from a *.csv file. \n",
    "\n",
    "[**sys**](https://docs.python.org/3/library/sys.html) module provides access to system-specific parameters and functions, allowing interaction with the Python runtime environment. It can be used to handle command-line arguments, manage the Python interpreter, and control input and output.\n",
    "In this project *sys* is used to redirect the standard output to a file instead to a terminal, as I will be writing the analysis to the text file called *[summary-analysis.txt](https://github.com/mondbr/pands-project/blob/main/summary_analysis.txt)*.\n",
    "\n",
    "[**NumPy**](https://numpy.org/doc/stable/user/absolute_beginners.html) is a fundamental Python library used for numerical computing. It provides support for large, multi-dimensional arrays and matrices, along with variety of mathematical functions to operate on these arrays. *NumPy* is widely used in various fields such as mathematics, statistics and data science.\n",
    "In this project *NumPy* is used to create a numerical arrays and analyse the correlation between numerical variables.\n",
    "\n",
    "[**myplotlib**](https://matplotlib.org/stable/) and its module [**pyplot**](https://matplotlib.org/stable/api/pyplot_summary.html) allows to work on mathematical calculations, array manipulations, creating plots and histograms. \n",
    "In this project *matplotlib.pyplot* is used to plot varoius of histograms and plots of the Iris data variables.\n",
    "\n",
    "[**seaborn**](https://seaborn.pydata.org/index.html) is another Python library built on to of Matplotlib. It is used for statistical data visualisation that helps to provide a nicely looking statistcal graphics.\n",
    "In this project *seaborn* is used for plotting plots and histograms for analysis. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset and DataFrame\n",
    "\n",
    "To work on the summary, I needed to find the data online and load it to my program. \n",
    "\n",
    "The below lines of code are used for reading the raw *.csv file available online and put into a DataFrame.\n",
    "\n",
    "A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional array, or a table with rows and columns.\n",
    "\n",
    "Raw file contains plain text format (Comma-Separated Values) of data that will be used for my analysis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the Iris online dataset (raw file)\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line loads the data into a DataFrame named *df*. This DataFrame contains all the columns that are in the CSV file. It is ready now to work on it in my analyis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to calculate and show statistical summary of numerical columns in some of my code, I created a new DataFrame below named *num_df* from an existing DataFrame *df*. I selected specific columns **'sepal_length', 'sepal_width', 'petal_length', 'petal_width'**, so my new DataFrame contains only these columns. I will need this in execution of a few Python methods in my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe selecting specific columns to be included in new data frame\n",
    "num_df = pd.DataFrame(df, columns=[\n",
    "                       'sepal_length','sepal_width','petal_length','petal_width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During my work on the code in this project and project for another module, I came accross warnings being shown on my terminal. They were related to *change in the figure layout in seaborn*. With discussing this with my ATU collegues and doing research I learnt that I can use below code to simply ignore the messages being prompted. \n",
    "\n",
    "This can be used for a cleaner output and no-distraction especially for scripts or notebooks where warnings are not critical and do not affect the results.\n",
    "\n",
    "However, while ignoring warnings can be helpful in certain situations, it's generally better to address warnings appropriately. Warnings often indicate potential issues in code or data. Ignoring them may hide important information that could tell diagnosing problems or improving quality of the code. \n",
    "\n",
    "I was reffering to the information provided on [docs.python](https://docs.python.org/3/library/warnings.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore warnings regarding a change in the figure layout in seaborn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will explain my approach to one of the task of this project, where I need to write my summary output to the single *.txt file. Initially I wanted to use *open()* function and *write()* method, however I found it difficult to include Python built-in functions such as *describe()* or *info()* etc, because .write() function only takes string value as an input \\\n",
    "\n",
    "After further research I learnt that more useful will be using *sys.stdout()* first to re-direct the standard output to a file. \n",
    "To be able to restore it later and come back to original output I created the below reference:\n",
    "\n",
    "I was reffering to the below sources: \\\n",
    "[geeksforgeeks.com](https://www.geeksforgeeks.org/sys-stdout-write-in-python/)\\\n",
    "[stackoverflow.com](https://stackoverflow.com/questions/3263672/the-difference-between-sys-stdout-write-and-print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a reference to the original standard output\n",
    "original_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My functions \n",
    "***\n",
    "To present my work in more structured way, I organised my code in this file by creating functions to break it for smaller parts for each task that are easier to work on and read.\n",
    "The knowledge how to do it I learnt throughout the module. \n",
    "\n",
    "The list of my functions are presented as follows and they are called out at the end of the file:\n",
    "\n",
    "- [*iris_correlation()*](#def iris_correlation)\n",
    "\n",
    "- *summary_file()*\n",
    "\n",
    "- *iris_barchart()*\n",
    "\n",
    "- *data_hist()*\n",
    "\n",
    "- *iris_histograms()*\n",
    "\n",
    "- *iris_scatterplots()*\n",
    "\n",
    "- *iris_pairplot()*\n",
    "\n",
    "- *iris_linespace()*\n",
    "\n",
    "- *iris_heatmap()*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redirecting to the text file\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *def iris_correlation()*\n",
    "\n",
    "My first function (although that was added later while working on the code) is *def iris_correlation():* \n",
    "I created this to assign the data into numpy arrays. I will need this later in my summary file, but also to calculate the correlation. \n",
    "\n",
    "References: \\\n",
    "Numpy arrays - ATU modules, [datacamp.com](https://www.datacamp.com/tutorial/python-numpy-tutorial) and [realpython.com](https://realpython.com/python-return-statement/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_correlation():\n",
    "        \n",
    "    # assigning data into numpy arrays. \n",
    "        s_len = df['sepal_length'].to_numpy()\n",
    "        s_wth = df['sepal_width'].to_numpy()\n",
    "        p_len = df['petal_length'].to_numpy()\n",
    "        p_wth = df['petal_width'].to_numpy()\n",
    "\n",
    "        # returning the values from a function so can be called out later and assigned to variables\n",
    "        return s_len, s_wth, p_len, p_wth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *def summary_file()*\n",
    "\n",
    "This is a function that is printing the output to the text file and provide varoius information about the dataset.\n",
    "\n",
    "I can use now *sys.stdout()* a default place to send a program’s text output and use print() function so all the output will be printed and saved in my dedicated .txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# creating a variable and assign a value to it - in this case a text file\\nFILENAME = 'summary_analysis.txt'\\n\\n    # using the stdout to redirect the standard output to a file\\n    # creating (if not already), opening the file with open()\\n    # w + t:  write/edit (w) mode, text (t) mode\\n    # assigning the opened file to sys.stdout, that \\n    # redirects all output that would normally go to the terminal, \\n    # but will go to the specified file.\\nsys.stdout = open (FILENAME, 'w+t') \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a variable and assign a value to it - in this case a text file\n",
    "FILENAME = 'summary_analysis.txt'\n",
    "\n",
    "    # using the stdout to redirect the standard output to a file\n",
    "    # creating (if not already), opening the file with open()\n",
    "    # w + t:  write/edit (w) mode, text (t) mode\n",
    "    # assigning the opened file to sys.stdout, that \n",
    "    # redirects all output that would normally go to the terminal, \n",
    "    # but will go to the specified file.\n",
    "sys.stdout = open (FILENAME, 'w+t') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my [**analysis.py**](https://github.com/mondbr/pands-project/blob/main/analysis.py) file \n",
    "I can now use varoius of functions and methods to show summary values of the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **print(df)** will give us an overview of the Iris dataset. We don't see the full table with entire data, but only a few rows. That does not mean we don't have that information. Rows that are out of screen are reffered as three dots. This way, we can see first five rows and last five rows of the table instead of presenting full table with entire data, but the information is still there.\n",
    "\n",
    "\n",
    "- **print(df.describe())** will give us basic statistical values for each variable: \n",
    "    - count - The number of not-empty values.\n",
    "    - mean - The average (mean) value.\n",
    "    - std - The standard deviation.\n",
    "    - min - The minimum value.\n",
    "    - 25% - The 25% percentile.\n",
    "    - 50% - The 50% percentile.\n",
    "    - 75% - The 75% percentile.\n",
    "    - max - The maximum value.\n",
    "\n",
    "- **print(df.info())** will give us a number of samples of each type and variable type. \n",
    "\n",
    "- **print(df['species'].value_counts())** will provide us with the number per selected category, in this case by spiecies. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also wanted to get more detailed statistical analysis, for example to display summary for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
